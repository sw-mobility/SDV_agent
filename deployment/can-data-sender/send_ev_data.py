import requests
import json
import time
import re
import os
import glob
import logging
from typing import Generator, Dict, Any
from datetime import datetime

# ==============================================================================
# ğŸŒŸ ë¡œê¹… ì„¤ì • ğŸŒŸ
# ==============================================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s:%(asctime)s:%(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ==============================================================================
# ğŸŒŸ í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì • (K8S Deploymentì—ì„œ ì£¼ì…ë¨) ğŸŒŸ
# ==============================================================================

# ì„œë²„ì˜ BASE URL (ì˜ˆ: http://192.168.8.131:30888)
SERVER_BASE_URL = os.environ.get("SERVER_BASE_URL", "http://127.0.0.1:5000")

# API ì—”ë“œí¬ì¸íŠ¸ ê²½ë¡œ (ì˜ˆ: /api/vehicle/realtime)
SERVER_END_POINT = os.environ.get("SERVER_END_POINT", "/api/vehicle/realtime")

# ìµœì¢… ì „ì†¡ URL êµ¬ì„±
SERVER_URL = f"{SERVER_BASE_URL}{SERVER_END_POINT}" 

# ë°ì´í„°ê°€ ì €ì¥ëœ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ (HostPath ë§ˆìš´íŠ¸ ê²½ë¡œ)
DATA_ROOT_DIR = os.environ.get("DATA_ROOT_DIR", "./daily_data")

# ì‹œë®¬ë ˆì´ì…˜ ì „ì†¡ ì£¼ê¸° (ì´ˆ)
TRANSMISSION_INTERVAL = int(os.environ.get("TRANSMISSION_INTERVAL", 10))
# ==============================================================================

def preprocess_mongo_json(line: str) -> str:
    """MongoDB Ext JSon ë¬¸ìì—´ì—ì„œ íŒŒì´ì¬ JSONìœ¼ë¡œ íŒŒì‹± ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    line = re.sub(r'ObjectId\("([0-9a-fA-F]+)"\)', r'"\1"', line)
    line = re.sub(r'ISODate\("([^"]+)"\)', r'"\1"', line)
    line = re.sub(r'NumberLong\(([\d-]+)\)', r'\1', line)
    line = re.sub(r'DBRef\("[^"]+", "([^"]+)"\)', r'"\1"', line)
    return line

def load_data_generator(file_path: str) -> Generator[Dict[str, Any], None, None]:
    """ë‹¨ì¼ íŒŒì¼ì—ì„œ ë¼ì¸ë³„ JSON ë°ì´í„°ë¥¼ ì½ê³  íŒŒì‹±í•˜ì—¬ ì œë„ˆë ˆì´í„°ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if not line.strip(): continue
                try:
                    processed_line = preprocess_mongo_json(line.strip())
                    document = json.loads(processed_line)
                    yield document
                except json.JSONDecodeError as e:
                    logger.warning(f"JSON íŒŒì‹± ì˜¤ë¥˜ (íŒŒì¼: {file_path}, ë¼ì¸ {i+1}): {e}")
                    continue
    except FileNotFoundError:
        logger.error(f"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    except Exception as e:
        logger.error(f"ì˜¤ë¥˜: íŒŒì¼ ë¡œë”© ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")


def get_sorted_daily_files(root_dir: str) -> list[str]:
    """ì§€ì •ëœ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  íŒŒì¼ì„ ì°¾ì•„ ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤."""
    file_paths = glob.glob(os.path.join(root_dir, '**', '*.txt'), recursive=True)
    if not file_paths:
        logger.warning(f"ê²½ê³ : ë°ì´í„° ë””ë ‰í† ë¦¬ '{root_dir}'ì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    file_paths.sort() 
    return file_paths


def extract_fields(full_doc: Dict[str, Any]) -> Dict[str, Any]:
    """ì›ë³¸ ë¬¸ì„œì—ì„œ ìš”êµ¬ë˜ëŠ” í•„ë“œë§Œ ì¶”ì¶œí•˜ì—¬ ì„œë²„ ì „ì†¡ìš© JSONì„ ìƒì„±í•©ë‹ˆë‹¤."""
    extracted = {
        "time": full_doc.get("time"),
        "vin": full_doc.get("vin"),
        "stateChanged": full_doc.get("stateChanged"),
        "car_data": full_doc.get("car_data", {}),
        "location_data": full_doc.get("location_data", {}),
        "extremeValue_data": full_doc.get("extremeValue_data", {}),
    }
    
    info_set_data = full_doc.get("powerBatteryInfoSet_data", {})
    if 'powerBatteryInfos' in info_set_data:
        # ì…€ ì „ë¥˜ê°’(cellAmperes) ì œì™¸
        cleaned_infos = []
        for info in info_set_data['powerBatteryInfos']:
            info_copy = info.copy() 
            if 'cellAmperes' in info_copy:
                del info_copy['cellAmperes']
            cleaned_infos.append(info_copy)
        info_set_data['powerBatteryInfos'] = cleaned_infos

    extracted["powerBatteryInfoSet_data"] = info_set_data
    return extracted


def send_data_to_server(payload: Dict[str, Any]):
    """ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ì„œë²„ë¡œ HTTP POST ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤."""
    try:
        response = requests.post(SERVER_URL, json=payload, timeout=5)
        
        if response.status_code == 200:
            logger.info(f"ì „ì†¡ ì„±ê³µ (URL: {SERVER_URL}, VIN: {payload.get('vin')}, Time: {payload.get('time')})")
        else:
            logger.warning(f"ì „ì†¡ ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code}, ì‘ë‹µ: {response.text})")
            
    except requests.exceptions.RequestException as e:
        logger.error(f"ì„œë²„ ì—°ê²° ì˜¤ë¥˜ ë°œìƒ: {e} (URL: {SERVER_URL})")


if __name__ == "__main__":
    logger.info("--- ì—£ì§€ ë””ë°”ì´ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ---")
    logger.info(f"ì„œë²„ URL: {SERVER_URL}")
    logger.info(f"ë°ì´í„° ë£¨íŠ¸ ë””ë ‰í† ë¦¬: {DATA_ROOT_DIR}")
    
    sorted_files = get_sorted_daily_files(DATA_ROOT_DIR)

    if not sorted_files:
        logger.warning("ì‹œë®¬ë ˆì´ì…˜ì„ ì‹œì‘í•  ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
    else:
        logger.info(f"ì´ {len(sorted_files)}ê°œì˜ ë°ì´í„° íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ìˆœì°¨ ì²˜ë¦¬ ì‹œì‘.")
        
        for file_path in sorted_files:
            logger.info(f"\n--- íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path} ---")
            
            data_gen = load_data_generator(file_path)
            
            for full_document in data_gen:
                try:
                    transmission_payload = extract_fields(full_document)
                    send_data_to_server(transmission_payload)
                    
                except Exception as e:
                    logger.error(f"ì‹œë®¬ë ˆì´ì…˜ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}")
                time.sleep(TRANSMISSION_INTERVAL)
            logger.info(f"--- íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {file_path} ---")
        logger.info("\n=== ëª¨ë“  íŒŒì¼ì˜ ë°ì´í„° ì „ì†¡ ì™„ë£Œ. ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ. ===")
